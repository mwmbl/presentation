<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Mwmbl, the Free Search Engine - a Technical Introduction</title>

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/black.css">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
	<!-- <section>Slide 1</section> -->
	<!-- <section>Slide 2</section> -->
	<section>
	  <h1>The challenges of building a non-profit search engine</h1>
<br>

<h3>Daoud Clarke</h3>

<br>
PyData Cardiff - 20th February 2023
	</section>
	<section>
	  <img class="stretch" src="img/daoud.jpg">
	</section>
	<section>
	  <img class="stretch" src="img/google-interview.png">
	</section>
	<section>
	  <img class="stretch" src="img/bing-interview.png">
	</section>
	<section>
	  <h3>Why do I have to see ads?</h3>
	  <img src="img/ads.png">
	</section>
	<section>
	  <h3>Why do I have to see a search results page?</h3>
	  <img src="img/obs.png">
	</section>
	<section>
	  <h1>December 2020</h1>
	  <h3>Stoatally Different</h3>
	</section>
	<section>
	  <pre><code data-trim data-noescape class="stretch">
SEARCH_URL = 'https://www.google.com/search'
AGENT = 'Mozilla/5.0'


def perform_search(query):
    response = requests.get(
        SEARCH_URL,
        params={'q': query, 'client': AGENT})

    urls, titles = process_search_results(response.content)
    return urls, titles


def process_search_results(html_content):
    soup = BeautifulSoup(html_content, features="html.parser")
    headlines = soup.select('h3')
    urls = []
    for headline in headlines:
        link = headline.parent
        url = link.get('href')
        urls.append(url)
    titles = [span.get_text() for span in headlines]
    assert len(urls) == len(titles)
    return urls, titles
	  </code></pre>
	</section>
	<section>
	  <pre><code data-trim data-noescape class="stretch">
COMPLETE_URL = \
    'http://suggestqueries.google.com/complete/search'


app = FastAPI()


@app.get("/complete")
def complete(q: str):
    response = requests.get(
        COMPLETE_URL,
        params={'q': q, 'client': 'firefox'})
    completions = response.json()[1]
    all_urls, all_titles = perform_search(q)
    completion = completions[0]
    urls, titles = perform_search(completion)
    all_urls += urls
    all_titles += titles
    return [q, all_titles]
	  </code></pre>
	</section>
	<section>
	  <h3>Why is it so slow?</h3>
	</section>
	<section>
	  <h3>Attempt 1: SQLite</h3>
	</section>
	<section>
	  <pre><code data-trim data-noescape class="stretch">
@app.get("/complete")
def complete(q: str):
    terms = [x.lower() for x in q.split()]

    completed = complete_term(terms[-1])
    terms = terms[:-1] + [completed]

    con = sqlite3.connect(INDEX_PATH)
    in_part = ','.join('?'*len(terms))
    query = f"""
        SELECT title, url
        FROM terms INNER JOIN documents
        ON terms.document_id = documents.id
        WHERE term IN ({in_part})
        GROUP BY title, url
        ORDER BY count(*) DESC, length(title)
        LIMIT 5
    """

    data = con.execute(query, terms).fetchall()

    results = [title.replace("\n", "") + ' â€” ' +
               url.replace("\n", "") for title, url in data]
    if len(results) == 0:
        return []
    return [q, results]
	  </code></pre>
	</section>

	<section>
	  <img class="stretch" src="img/latency-1.png">
	</section>
	<section>
	  <img class="stretch" src="img/latency-2.png">
	</section>
	<section>
	  <img class="stretch" src="img/latency-3.png">
	</section>
	<section>
	  <img class="stretch" src="img/latency-4.png">
	</section>
	<section>
	  <h3>What's the worst case number of reads?</h3>
	  <pre><code data-trim data-noescape class="stretch">
        SELECT title, url
        FROM terms INNER JOIN documents
        ON terms.document_id = documents.id
        WHERE term IN ({in_part})
        GROUP BY title, url
        ORDER BY count(*) DESC, length(title)
        LIMIT 5
	  </code></pre>
	</section>

	<section>
	  <h3>We need a new architecture</h3>
	</section>

	<section>
	  <img class="stretch" src="img/page-def.png">
	</section>

	<section data-background-size="contain" data-background-image="img/tiny-storage.svg" data-background-color="white"></section>

	<section>
	  <pre><code data-trim data-noescape class="stretch">
def get_key_page_index(self, key) -> int:
    key_hash = mmh3.hash(key, signed=False)
    return key_hash % self.num_pages
	  </code></pre>
	  <span>"apple" => 1680</span>
	</section>

	<section>
	  <pre><code data-trim data-noescape class="stretch">
def _get_page_tuples(self, i):
    page_data = self.mmap[
        i * self.page_size +
        METADATA_SIZE:(i + 1) * self.page_size
        + METADATA_SIZE]
    try:
        decompressed_data = self.decompressor.decompress(
            page_data)
    except ZstdError:
        logger.exception(f"Error decompressing: {page_data}")
        return []
    return json.loads(decompressed_data.decode('utf8'))
	  </code></pre>
	</section>

	<section data-background-size="contain" data-background-image="img/page.png" data-background-color="#300a24"></section>
	<section data-background-size="contain" data-background-image="img/page-2.png" data-background-color="#300a24"></section>

	<section>
	  <ul>
	    <li> Query: "open broadcaster software"
	    <li> Look up:
	      <ul>
		<li> open
		<li> broadcaster
		<li> software
		<li> open broadcaster
		<li> broadcaster software
	      </ul>
	  </ul>
	</section>

	<section>
	  <h3>What is the maximum number of reads?</h3>
	</section>

	<section>
	  <h3>Will it work?</h3>
	</section>

	<section>
	  <ul>
	    <li> We fit around 23 results in one page of 4096 bytes
	    <li> Google indexes around 100 billion pages per locale
	    <li> We would need an index of around 16 terabytes
	  </ul>
	</section>	

	<section>
	  <h3>How can we reduce crawling costs?</h3>
	</section>

	<section>
	  <pre><code data-trim data-noescape class="stretch">
@router.post('/batches/new')
def request_new_batch(batch_request: NewBatchRequest) \
    -> list[str]:
    ...

@router.post('/batches/')
def post_batch(batch: Batch):
    ...
	  </code></pre>
	</section>
	
	<section>
	  <h3>Will it work?</h3>
	</section>

	<section>
	  <ul>
	    <li> We are currently crawling around 1 million pages a day
	    <li> We currently have about 26 active volunteers
	    <li> We want our index of 100 billion pages to be refreshed at least once a month
	    <li> We need to crawl around 3 billion pages a day
	  </ul>
	</section>	

	<section>
	  <h3>But will it work?</h3>
	</section>
	
	<section>
	  <h3>How to fly (or build a search engine)</h3>
	  <i style="font-style: italic !important">Do not listen to what anybody says to you at this point because they are unlikely to say anything helpful. They are most likely to say something along the lines of "Good God, you can't possibly be flying!"</i>
	  <br><br>
	  <span style="color: red"><i style="font-style: italic !important">It is vitally important not to believe them or they will suddenly be right.</i> </span>
	  <br><br>
	  - Douglas Adams
	</section>
	
	<section data-background-image="img/larry-page.png">
	  <h3>Why should the gateway to the world's knowledge be in the hands of a corporation?</h3>
	</section>
	
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
	  hash: true,

	  // Learn about plugins: https://revealjs.com/plugins/
	  plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
      });
    </script>
  </body>
</html>
